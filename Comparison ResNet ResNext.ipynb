{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Porsche_Interview.ipynb","provenance":[],"authorship_tag":"ABX9TyP1dFjbohX5Eq2oJEotV+XF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41a9ymHbI2ng","executionInfo":{"status":"ok","timestamp":1660591844697,"user_tz":-480,"elapsed":21355,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"cc13becb-fbff-4575-c9f6-d069a507e3a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["['Dataset',\n"," 'best_weight.pt',\n"," 'saved_val_acc.txt',\n"," 'runs',\n"," 'models',\n"," 'Untitled0.ipynb',\n"," 'Porsche_Interview.ipynb']"]},"metadata":{},"execution_count":1}],"source":["#Colab setting directory\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","os.chdir('/content/drive/My Drive/Porsche_interview') #Change the directory\n","os.listdir() #list the directory"]},{"cell_type":"code","source":["!wget -P Dataset/ https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","!tar -xzvf {Dataset_root + '/cifar-100-python.tar.gz'}\n","!rm {Dataset_root + '/cifar-100-python.tar.gz'}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tbsuoc7AMXVK","executionInfo":{"status":"ok","timestamp":1660210312488,"user_tz":-480,"elapsed":8923,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"ffd33300-2e77-43d3-b0eb-437b9f932828"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-11 09:31:44--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 169001437 (161M) [application/x-gzip]\n","Saving to: ‘Dataset/cifar-100-python.tar.gz’\n","\n","cifar-100-python.ta 100%[===================>] 161.17M  57.5MB/s    in 2.8s    \n","\n","2022-08-11 09:31:49 (57.5 MB/s) - ‘Dataset/cifar-100-python.tar.gz’ saved [169001437/169001437]\n","\n","cifar-100-python/\n","cifar-100-python/file.txt~\n","cifar-100-python/train\n","cifar-100-python/test\n","cifar-100-python/meta\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"f3p7ZJ34kjhv"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","from torchsummary import summary\n","from torch.optim import lr_scheduler"],"metadata":{"id":"buw-QWg7Qmjq","executionInfo":{"status":"ok","timestamp":1660591852459,"user_tz":-480,"elapsed":4145,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["Dataset_Dir = \"./Dataset\"\n","input_size = 224"],"metadata":{"id":"jr_S2P4SjVGo","executionInfo":{"status":"ok","timestamp":1660591854390,"user_tz":-480,"elapsed":287,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(), \n","        transforms.ToTensor(),\n","        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n","    ])\n","}\n","\n","# image_datasets = {x: datasets.ImageFolder(os.path.join(Dataset_Dir, x), data_transforms[x]) for x in ['train', 'val']}\n","# image_datasets = {x: datasets.ImageFolder(os.path.join(Dataset_Dir, x), data_transforms[x]) for x in ['train', 'val']}\n","\n","# dataloader_dict = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","# image_datasets = datasets.CIFAR100(Dataset_Dir, train=True, transform=data_transforms['train'])\n","\n","train_set = datasets.CIFAR100(Dataset_Dir, train=True, transform=data_transforms['train'])\n","val_set = datasets.CIFAR100(Dataset_Dir, train=False, transform=data_transforms['val'])\n","data_loader = {'train': DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2), 'val': DataLoader(val_set, batch_size=32, shuffle=False, num_workers=2)}\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"7mDnASnboged","executionInfo":{"status":"ok","timestamp":1660591864333,"user_tz":-480,"elapsed":7202,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def initialize_model(model_name, num_classes, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","\n","    if model_name == \"resnet\":\n","        \"\"\" Resnet18\n","        \"\"\"\n","        model_ft = models.resnet18(pretrained=use_pretrained, progress=True)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","    elif model_name == \"wrn\":\n","        model_ft = models.wide_resnet50_2(pretrained=use_pretrained, progress=True)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","    elif model_name == \"mobile\":\n","        model_ft = models.mobilenet_v3_large(pretrained=use_pretrained, progress=True)\n","        num_ftrs = model_ft.classifier[3].in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","    elif model_name == \"resnext\":\n","        model_ft = models.resnext50_32x4d(pretrained=use_pretrained, progress=True)\n","        num_ftrs = model_ft.fc.in_features\n","        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","    \n","    return model_ft\n","\n","# model_name = \"resnet\"\n","# model_name = \"mobile\"\n","model_name = \"resnext\"\n","num_classes = 100\n","use_pretrained = False\n","\n","\n","# Initialize the model for this run\n","model_ft = initialize_model(model_name, num_classes, use_pretrained)\n","\n","# Print the model we just instantiated"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yt9cs542kRKf","executionInfo":{"status":"ok","timestamp":1660591868499,"user_tz":-480,"elapsed":1254,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"0d0a168d-c364-46e1-d96b-a3108e1663e1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["datetime.now()\n","a = \"./models/\" + str(datetime.now()) + \"/best_weight.pt\"\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Jhy20qB_ZW4k","executionInfo":{"status":"ok","timestamp":1660397493175,"user_tz":-480,"elapsed":26,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"b6eb9732-b2b3-4752-f9fe-1a98a266f850"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./models/2022-08-13 13:31:33.933332/best_weight.pt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, from_epoch=0):\n","    since = time.time()\n","\n","    val_acc_history = []\n","    \n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    weight_folder = \"./models/\" + str(datetime.now())\n","    os.makedirs(weight_folder)\n","    writer = SummaryWriter()\n","    # scheduler = lr_scheduler.LinearLR(optimizer, 0.5, 1, 30)\n","    for epoch in range(from_epoch, num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                torch.save(model, weight_folder+'/best_weight.pt')\n","\n","            if phase == 'train':\n","                train_loss = epoch_loss\n","                train_acc = epoch_acc\n","            else:\n","                val_loss = epoch_loss\n","                val_acc = epoch_acc\n","\n","        writer.add_scalars('loss', {\n","            'train_loss': train_loss,\n","            'val_loss': val_loss\n","        }, epoch+1)\n","        writer.add_scalars('accuracy', {\n","            'train_accuracy': train_acc,\n","            'val_accuracy': val_acc            \n","        }, epoch+1)\n","        \n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"],"metadata":{"id":"sbfu4fhylKsU","executionInfo":{"status":"ok","timestamp":1660591874407,"user_tz":-480,"elapsed":281,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["scratch_model, _ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n","scartch_model = scratch_model.to(device)\n","scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n","scratch_criterion = nn.CrossEntropyLoss()\n","num_epochs = 100\n","_,scratch_hist = train_model(scratch_model, data_loader, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uqQytoDCv7ks","outputId":"1a74106c-0e30-4b7d-c667-7984ff24aae2"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","----------\n","train Loss: 4.0665 Acc: 0.0799\n","val Loss: 3.6619 Acc: 0.1379\n","\n","Epoch 2/100\n","----------\n","train Loss: 3.7117 Acc: 0.1348\n","val Loss: 3.3419 Acc: 0.1969\n","\n","Epoch 3/100\n","----------\n","train Loss: 3.5002 Acc: 0.1689\n","val Loss: 3.1087 Acc: 0.2399\n","\n","Epoch 4/100\n","----------\n","train Loss: 3.3130 Acc: 0.2013\n","val Loss: 2.9492 Acc: 0.2725\n","\n","Epoch 5/100\n","----------\n","train Loss: 3.1493 Acc: 0.2308\n","val Loss: 2.7907 Acc: 0.2996\n","\n","Epoch 6/100\n","----------\n","train Loss: 2.9945 Acc: 0.2611\n","val Loss: 2.6113 Acc: 0.3382\n","\n","Epoch 7/100\n","----------\n","train Loss: 2.8693 Acc: 0.2888\n","val Loss: 2.6449 Acc: 0.3346\n","\n","Epoch 8/100\n","----------\n","train Loss: 2.7554 Acc: 0.3111\n","val Loss: 2.3170 Acc: 0.3970\n","\n","Epoch 9/100\n","----------\n","train Loss: 2.6353 Acc: 0.3354\n","val Loss: 2.2131 Acc: 0.4186\n","\n","Epoch 10/100\n","----------\n","train Loss: 2.5459 Acc: 0.3542\n","val Loss: 2.1460 Acc: 0.4341\n","\n","Epoch 11/100\n","----------\n","train Loss: 2.4660 Acc: 0.3697\n","val Loss: 2.0810 Acc: 0.4481\n","\n","Epoch 12/100\n","----------\n","train Loss: 2.3556 Acc: 0.3928\n","val Loss: 1.9418 Acc: 0.4838\n","\n","Epoch 13/100\n","----------\n","train Loss: 2.3096 Acc: 0.4072\n","val Loss: 1.9543 Acc: 0.4753\n","\n","Epoch 14/100\n","----------\n","train Loss: 2.2484 Acc: 0.4172\n","val Loss: 1.8162 Acc: 0.5092\n","\n","Epoch 15/100\n","----------\n","train Loss: 2.1877 Acc: 0.4326\n","val Loss: 1.7495 Acc: 0.5230\n","\n","Epoch 16/100\n","----------\n","train Loss: 2.1320 Acc: 0.4454\n","val Loss: 1.7151 Acc: 0.5351\n","\n","Epoch 17/100\n","----------\n","train Loss: 2.0850 Acc: 0.4531\n","val Loss: 1.6933 Acc: 0.5390\n","\n","Epoch 18/100\n","----------\n","train Loss: 2.0301 Acc: 0.4671\n","val Loss: 1.6885 Acc: 0.5384\n","\n","Epoch 19/100\n","----------\n","train Loss: 1.9893 Acc: 0.4775\n","val Loss: 1.6743 Acc: 0.5432\n","\n","Epoch 20/100\n","----------\n","train Loss: 1.9611 Acc: 0.4834\n","val Loss: 1.5964 Acc: 0.5597\n","\n","Epoch 21/100\n","----------\n","train Loss: 1.9069 Acc: 0.4972\n","val Loss: 1.5677 Acc: 0.5715\n","\n","Epoch 22/100\n","----------\n","train Loss: 1.8768 Acc: 0.5055\n","val Loss: 1.5346 Acc: 0.5773\n","\n","Epoch 23/100\n","----------\n","train Loss: 1.8476 Acc: 0.5125\n","val Loss: 1.4927 Acc: 0.5902\n","\n","Epoch 24/100\n","----------\n","train Loss: 1.8102 Acc: 0.5213\n","val Loss: 1.4557 Acc: 0.5940\n","\n","Epoch 25/100\n","----------\n","train Loss: 1.7774 Acc: 0.5263\n","val Loss: 1.4848 Acc: 0.5883\n","\n","Epoch 26/100\n","----------\n","train Loss: 1.7561 Acc: 0.5336\n","val Loss: 1.4074 Acc: 0.6065\n","\n","Epoch 27/100\n","----------\n","train Loss: 1.7198 Acc: 0.5411\n","val Loss: 1.4632 Acc: 0.5978\n","\n","Epoch 28/100\n","----------\n","train Loss: 1.6984 Acc: 0.5479\n","val Loss: 1.4452 Acc: 0.6030\n","\n","Epoch 29/100\n","----------\n","train Loss: 1.6741 Acc: 0.5537\n","val Loss: 1.3949 Acc: 0.6127\n","\n","Epoch 30/100\n","----------\n","train Loss: 1.6501 Acc: 0.5571\n","val Loss: 1.4085 Acc: 0.6127\n","\n","Epoch 31/100\n","----------\n","train Loss: 1.6205 Acc: 0.5643\n","val Loss: 1.3609 Acc: 0.6266\n","\n","Epoch 32/100\n","----------\n","train Loss: 1.6043 Acc: 0.5698\n","val Loss: 1.3293 Acc: 0.6341\n","\n","Epoch 33/100\n","----------\n","train Loss: 1.5825 Acc: 0.5772\n","val Loss: 1.2910 Acc: 0.6403\n","\n","Epoch 34/100\n","----------\n","train Loss: 1.5505 Acc: 0.5837\n","val Loss: 1.3122 Acc: 0.6383\n","\n","Epoch 35/100\n","----------\n","train Loss: 1.5495 Acc: 0.5833\n","val Loss: 1.3038 Acc: 0.6394\n","\n","Epoch 36/100\n","----------\n","train Loss: 1.5113 Acc: 0.5914\n","val Loss: 1.2729 Acc: 0.6447\n","\n","Epoch 37/100\n","----------\n","train Loss: 1.4946 Acc: 0.5962\n","val Loss: 1.3134 Acc: 0.6387\n","\n","Epoch 38/100\n","----------\n","train Loss: 1.4716 Acc: 0.6006\n","val Loss: 1.2630 Acc: 0.6524\n","\n","Epoch 39/100\n","----------\n","train Loss: 1.4605 Acc: 0.6047\n","val Loss: 1.2855 Acc: 0.6529\n","\n","Epoch 40/100\n","----------\n","train Loss: 1.4418 Acc: 0.6102\n","val Loss: 1.2554 Acc: 0.6542\n","\n","Epoch 41/100\n","----------\n","train Loss: 1.4316 Acc: 0.6125\n","val Loss: 1.2631 Acc: 0.6484\n","\n","Epoch 42/100\n","----------\n","train Loss: 1.3919 Acc: 0.6223\n","val Loss: 1.2382 Acc: 0.6590\n","\n","Epoch 43/100\n","----------\n","train Loss: 1.3957 Acc: 0.6199\n","val Loss: 1.2659 Acc: 0.6558\n","\n","Epoch 44/100\n","----------\n","train Loss: 1.3794 Acc: 0.6266\n","val Loss: 1.2172 Acc: 0.6644\n","\n","Epoch 45/100\n","----------\n","train Loss: 1.3533 Acc: 0.6313\n","val Loss: 1.2427 Acc: 0.6643\n","\n","Epoch 46/100\n","----------\n","train Loss: 1.3382 Acc: 0.6362\n","val Loss: 1.2655 Acc: 0.6619\n","\n","Epoch 47/100\n","----------\n","train Loss: 1.3372 Acc: 0.6376\n","val Loss: 1.2369 Acc: 0.6645\n","\n","Epoch 48/100\n","----------\n","train Loss: 1.2986 Acc: 0.6441\n","val Loss: 1.1771 Acc: 0.6763\n","\n","Epoch 49/100\n","----------\n","train Loss: 1.2975 Acc: 0.6474\n","val Loss: 1.1843 Acc: 0.6774\n","\n","Epoch 50/100\n","----------\n","train Loss: 1.2877 Acc: 0.6498\n","val Loss: 1.2353 Acc: 0.6679\n","\n","Epoch 51/100\n","----------\n","train Loss: 1.2678 Acc: 0.6548\n","val Loss: 1.2087 Acc: 0.6762\n","\n","Epoch 52/100\n","----------\n","train Loss: 1.2561 Acc: 0.6575\n","val Loss: 1.2172 Acc: 0.6758\n","\n","Epoch 53/100\n","----------\n","train Loss: 1.2290 Acc: 0.6632\n","val Loss: 1.2039 Acc: 0.6758\n","\n","Epoch 54/100\n","----------\n","train Loss: 1.2231 Acc: 0.6684\n","val Loss: 1.1965 Acc: 0.6777\n","\n","Epoch 55/100\n","----------\n","train Loss: 1.2116 Acc: 0.6687\n","val Loss: 1.1876 Acc: 0.6788\n","\n","Epoch 56/100\n","----------\n","train Loss: 1.2039 Acc: 0.6713\n","val Loss: 1.1797 Acc: 0.6846\n","\n","Epoch 57/100\n","----------\n","train Loss: 1.1863 Acc: 0.6757\n","val Loss: 1.1778 Acc: 0.6839\n","\n","Epoch 58/100\n","----------\n","train Loss: 1.1711 Acc: 0.6792\n","val Loss: 1.1464 Acc: 0.6866\n","\n","Epoch 59/100\n","----------\n","train Loss: 1.1545 Acc: 0.6828\n","val Loss: 1.1901 Acc: 0.6818\n","\n","Epoch 60/100\n","----------\n","train Loss: 1.1540 Acc: 0.6841\n","val Loss: 1.2208 Acc: 0.6820\n","\n","Epoch 61/100\n","----------\n","train Loss: 1.1395 Acc: 0.6885\n","val Loss: 1.1948 Acc: 0.6875\n","\n","Epoch 62/100\n","----------\n","train Loss: 1.1186 Acc: 0.6947\n","val Loss: 1.1879 Acc: 0.6899\n","\n","Epoch 63/100\n","----------\n","train Loss: 1.1270 Acc: 0.6908\n","val Loss: 1.1816 Acc: 0.6865\n","\n","Epoch 64/100\n","----------\n","train Loss: 1.1017 Acc: 0.6971\n","val Loss: 1.2100 Acc: 0.6874\n","\n","Epoch 65/100\n","----------\n","train Loss: 1.0969 Acc: 0.6976\n","val Loss: 1.2033 Acc: 0.6876\n","\n","Epoch 66/100\n","----------\n","train Loss: 1.0736 Acc: 0.7055\n","val Loss: 1.1588 Acc: 0.6943\n","\n","Epoch 67/100\n","----------\n","train Loss: 1.0671 Acc: 0.7081\n","val Loss: 1.1654 Acc: 0.6948\n","\n","Epoch 68/100\n","----------\n","train Loss: 1.0612 Acc: 0.7091\n","val Loss: 1.2197 Acc: 0.6842\n","\n","Epoch 69/100\n","----------\n","train Loss: 1.0620 Acc: 0.7091\n","val Loss: 1.2014 Acc: 0.6893\n","\n","Epoch 70/100\n","----------\n","train Loss: 1.0357 Acc: 0.7161\n","val Loss: 1.1828 Acc: 0.6966\n","\n","Epoch 71/100\n","----------\n","train Loss: 1.0373 Acc: 0.7161\n","val Loss: 1.1853 Acc: 0.6908\n","\n","Epoch 72/100\n","----------\n"]}]},{"cell_type":"code","source":["scratch_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","scartch_model = scratch_model.to(device)\n","scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n","scratch_criterion = nn.CrossEntropyLoss()\n","num_epochs = 100\n","_,scratch_hist = train_model(scratch_model, data_loader, scratch_criterion, scratch_optimizer, num_epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rn_aIVoLl5vf","outputId":"847cb62e-b7e0-48ce-98d4-70aa8f1c4d64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","----------\n","train Loss: 4.0548 Acc: 0.0819\n","val Loss: 3.7310 Acc: 0.1359\n","\n","Epoch 2/100\n","----------\n","train Loss: 3.7219 Acc: 0.1356\n","val Loss: 3.3633 Acc: 0.1933\n","\n","Epoch 3/100\n","----------\n","train Loss: 3.5099 Acc: 0.1694\n","val Loss: 3.1361 Acc: 0.2378\n","\n","Epoch 4/100\n","----------\n","train Loss: 3.3324 Acc: 0.1994\n","val Loss: 2.9173 Acc: 0.2767\n","\n","Epoch 5/100\n","----------\n","train Loss: 3.1554 Acc: 0.2325\n","val Loss: 2.7365 Acc: 0.3091\n","\n","Epoch 6/100\n","----------\n","train Loss: 3.0109 Acc: 0.2572\n","val Loss: 2.6117 Acc: 0.3340\n","\n","Epoch 7/100\n","----------\n","train Loss: 2.8790 Acc: 0.2855\n","val Loss: 2.4562 Acc: 0.3714\n","\n","Epoch 8/100\n","----------\n","train Loss: 2.7593 Acc: 0.3106\n","val Loss: 2.3348 Acc: 0.3929\n","\n","Epoch 9/100\n","----------\n","train Loss: 2.6535 Acc: 0.3325\n","val Loss: 2.2171 Acc: 0.4211\n","\n","Epoch 10/100\n","----------\n","train Loss: 2.5542 Acc: 0.3525\n","val Loss: 2.2216 Acc: 0.4278\n","\n","Epoch 11/100\n","----------\n","train Loss: 2.4739 Acc: 0.3696\n","val Loss: 2.0549 Acc: 0.4626\n","\n","Epoch 12/100\n","----------\n","train Loss: 2.3938 Acc: 0.3857\n","val Loss: 2.0273 Acc: 0.4610\n","\n","Epoch 13/100\n","----------\n","train Loss: 2.3197 Acc: 0.4029\n","val Loss: 1.8935 Acc: 0.4983\n","\n","Epoch 14/100\n","----------\n","train Loss: 2.2589 Acc: 0.4167\n","val Loss: 1.8688 Acc: 0.5019\n","\n","Epoch 15/100\n","----------\n","train Loss: 2.2008 Acc: 0.4294\n","val Loss: 1.7944 Acc: 0.5172\n","\n","Epoch 16/100\n","----------\n","train Loss: 2.1385 Acc: 0.4439\n","val Loss: 1.7446 Acc: 0.5290\n","\n","Epoch 17/100\n","----------\n","train Loss: 2.0957 Acc: 0.4540\n","val Loss: 1.7056 Acc: 0.5417\n","\n","Epoch 18/100\n","----------\n","train Loss: 2.0523 Acc: 0.4650\n","val Loss: 1.7942 Acc: 0.5230\n","\n","Epoch 19/100\n","----------\n","train Loss: 2.0042 Acc: 0.4753\n","val Loss: 1.6854 Acc: 0.5419\n","\n","Epoch 20/100\n","----------\n","train Loss: 1.9629 Acc: 0.4845\n","val Loss: 1.6219 Acc: 0.5627\n","\n","Epoch 21/100\n","----------\n","train Loss: 1.9299 Acc: 0.4902\n","val Loss: 1.5407 Acc: 0.5770\n","\n","Epoch 22/100\n","----------\n","train Loss: 1.8890 Acc: 0.4983\n","val Loss: 1.5177 Acc: 0.5864\n","\n","Epoch 23/100\n","----------\n","train Loss: 1.8461 Acc: 0.5114\n","val Loss: 1.5499 Acc: 0.5813\n","\n","Epoch 24/100\n","----------\n","train Loss: 1.8131 Acc: 0.5185\n","val Loss: 1.4835 Acc: 0.5978\n","\n","Epoch 25/100\n","----------\n","train Loss: 1.7919 Acc: 0.5268\n","val Loss: 1.5081 Acc: 0.5852\n","\n","Epoch 26/100\n","----------\n","train Loss: 1.7626 Acc: 0.5318\n","val Loss: 1.4868 Acc: 0.5982\n","\n","Epoch 27/100\n","----------\n","train Loss: 1.7352 Acc: 0.5417\n","val Loss: 1.4512 Acc: 0.6053\n","\n","Epoch 28/100\n","----------\n","train Loss: 1.6948 Acc: 0.5493\n","val Loss: 1.3823 Acc: 0.6190\n","\n","Epoch 29/100\n","----------\n","train Loss: 1.6776 Acc: 0.5506\n","val Loss: 1.4218 Acc: 0.6158\n","\n","Epoch 30/100\n","----------\n","train Loss: 1.6544 Acc: 0.5562\n","val Loss: 1.3699 Acc: 0.6195\n","\n","Epoch 31/100\n","----------\n","train Loss: 1.6267 Acc: 0.5628\n","val Loss: 1.3727 Acc: 0.6240\n","\n","Epoch 32/100\n","----------\n","train Loss: 1.5989 Acc: 0.5709\n","val Loss: 1.3941 Acc: 0.6277\n","\n","Epoch 33/100\n","----------\n","train Loss: 1.5865 Acc: 0.5744\n","val Loss: 1.3507 Acc: 0.6323\n","\n","Epoch 34/100\n","----------\n","train Loss: 1.5538 Acc: 0.5806\n","val Loss: 1.2669 Acc: 0.6540\n","\n","Epoch 35/100\n","----------\n","train Loss: 1.5448 Acc: 0.5858\n","val Loss: 1.3262 Acc: 0.6407\n","\n","Epoch 36/100\n","----------\n","train Loss: 1.5238 Acc: 0.5889\n","val Loss: 1.3078 Acc: 0.6497\n","\n","Epoch 37/100\n","----------\n","train Loss: 1.5031 Acc: 0.5956\n","val Loss: 1.3165 Acc: 0.6408\n","\n","Epoch 38/100\n","----------\n","train Loss: 1.4736 Acc: 0.6013\n","val Loss: 1.2999 Acc: 0.6467\n","\n","Epoch 39/100\n","----------\n","train Loss: 1.4736 Acc: 0.6019\n","val Loss: 1.2843 Acc: 0.6529\n","\n","Epoch 40/100\n","----------\n","train Loss: 1.4468 Acc: 0.6086\n","val Loss: 1.3029 Acc: 0.6456\n","\n","Epoch 41/100\n","----------\n","train Loss: 1.4264 Acc: 0.6140\n","val Loss: 1.2860 Acc: 0.6522\n","\n","Epoch 42/100\n","----------\n","train Loss: 1.4132 Acc: 0.6166\n","val Loss: 1.2662 Acc: 0.6505\n","\n","Epoch 43/100\n","----------\n","train Loss: 1.3874 Acc: 0.6212\n","val Loss: 1.2718 Acc: 0.6536\n","\n","Epoch 44/100\n","----------\n","train Loss: 1.3783 Acc: 0.6244\n","val Loss: 1.2556 Acc: 0.6575\n","\n","Epoch 45/100\n","----------\n","train Loss: 1.3697 Acc: 0.6293\n","val Loss: 1.2413 Acc: 0.6554\n","\n","Epoch 46/100\n","----------\n","train Loss: 1.3440 Acc: 0.6355\n","val Loss: 1.2357 Acc: 0.6632\n","\n","Epoch 47/100\n","----------\n","train Loss: 1.3209 Acc: 0.6386\n","val Loss: 1.2248 Acc: 0.6651\n","\n","Epoch 48/100\n","----------\n","train Loss: 1.3166 Acc: 0.6419\n","val Loss: 1.2703 Acc: 0.6616\n","\n","Epoch 49/100\n","----------\n","train Loss: 1.3063 Acc: 0.6447\n","val Loss: 1.2275 Acc: 0.6706\n","\n","Epoch 50/100\n","----------\n","train Loss: 1.2770 Acc: 0.6505\n","val Loss: 1.2104 Acc: 0.6748\n","\n","Epoch 51/100\n","----------\n","train Loss: 1.2796 Acc: 0.6503\n","val Loss: 1.2517 Acc: 0.6685\n","\n","Epoch 52/100\n","----------\n","train Loss: 1.2675 Acc: 0.6575\n","val Loss: 1.2390 Acc: 0.6690\n","\n","Epoch 53/100\n","----------\n","train Loss: 1.2369 Acc: 0.6634\n","val Loss: 1.1985 Acc: 0.6784\n","\n","Epoch 54/100\n","----------\n","train Loss: 1.2475 Acc: 0.6602\n","val Loss: 1.2240 Acc: 0.6759\n","\n","Epoch 55/100\n","----------\n","train Loss: 1.2084 Acc: 0.6696\n","val Loss: 1.2250 Acc: 0.6725\n","\n","Epoch 56/100\n","----------\n","train Loss: 1.2047 Acc: 0.6727\n","val Loss: 1.1797 Acc: 0.6814\n","\n","Epoch 57/100\n","----------\n","train Loss: 1.1775 Acc: 0.6769\n","val Loss: 1.1921 Acc: 0.6817\n","\n","Epoch 58/100\n","----------\n","train Loss: 1.1862 Acc: 0.6767\n","val Loss: 1.2402 Acc: 0.6759\n","\n","Epoch 59/100\n","----------\n","train Loss: 1.1790 Acc: 0.6790\n","val Loss: 1.1949 Acc: 0.6848\n","\n","Epoch 60/100\n","----------\n","train Loss: 1.1564 Acc: 0.6818\n","val Loss: 1.2358 Acc: 0.6715\n","\n","Epoch 61/100\n","----------\n","train Loss: 1.1380 Acc: 0.6881\n"]}]},{"cell_type":"code","source":["continued_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","continued_model.load_state_dict(torch.load('best_weight.pt').state_dict())\n","continued_model = continued_model.to(device)\n","continued_optimizer = optim.SGD(continued_model.parameters(), lr=0.001, momentum=0.9)\n","continued_criterion = nn.CrossEntropyLoss()\n","num_epochs = 100\n","model ,continued_hist = train_model(continued_model, data_loader, continued_criterion, continued_optimizer, num_epochs=num_epochs, from_epoch=59)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":413},"id":"efTS5kD6TW9H","executionInfo":{"status":"error","timestamp":1660398722959,"user_tz":-480,"elapsed":528,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"480aac9e-5a4f-4dc4-88be-d7bf25f03468"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-82e95fa20108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontinued_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcontinued_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinued_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m59\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-be37d5254806>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, from_epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mweight_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./models/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/2022-08-13 13:52:03.606181'"]}]},{"cell_type":"code","source":["test_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","test_model.load_state_dict(torch.load('best_weight.pt').state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xtk66L_YBf8","executionInfo":{"status":"ok","timestamp":1660380706547,"user_tz":-480,"elapsed":520,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"184b68fb-1314-493f-aeca-954aea350a8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["continued_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","continued_model.load_state_dict(torch.load('best_weight.pt').state_dict())\n","continued_model = continued_model.to(device)\n","continued_optimizer = optim.SGD(continued_model.parameters(), lr=0.0001, momentum=0.9)\n","continued_criterion = nn.CrossEntropyLoss()\n","num_epochs = 200\n","model ,continued_hist = train_model(continued_model, data_loader, continued_criterion, continued_optimizer, num_epochs=num_epochs, from_epoch=100)"],"metadata":{"id":"-yBs2CuoVwbn","executionInfo":{"status":"error","timestamp":1660409923961,"user_tz":-480,"elapsed":5741458,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ecaaec64-b590-485a-c82c-fc14cf8fc90a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 101/200\n","----------\n","train Loss: 0.7818 Acc: 0.7888\n","val Loss: 1.1036 Acc: 0.7271\n","\n","Epoch 102/200\n","----------\n","train Loss: 0.7323 Acc: 0.8038\n","val Loss: 1.0855 Acc: 0.7278\n","\n","Epoch 103/200\n","----------\n","train Loss: 0.7250 Acc: 0.8062\n","val Loss: 1.0931 Acc: 0.7283\n","\n","Epoch 104/200\n","----------\n","train Loss: 0.7203 Acc: 0.8056\n","val Loss: 1.0850 Acc: 0.7321\n","\n","Epoch 105/200\n","----------\n","train Loss: 0.7148 Acc: 0.8077\n","val Loss: 1.0853 Acc: 0.7291\n","\n","Epoch 106/200\n","----------\n","train Loss: 0.7093 Acc: 0.8085\n","val Loss: 1.0768 Acc: 0.7311\n","\n","Epoch 107/200\n","----------\n","train Loss: 0.6901 Acc: 0.8157\n","val Loss: 1.0898 Acc: 0.7310\n","\n","Epoch 108/200\n","----------\n","train Loss: 0.6971 Acc: 0.8146\n","val Loss: 1.0925 Acc: 0.7289\n","\n","Epoch 109/200\n","----------\n","train Loss: 0.6874 Acc: 0.8154\n","val Loss: 1.0795 Acc: 0.7338\n","\n","Epoch 110/200\n","----------\n","train Loss: 0.6951 Acc: 0.8139\n","val Loss: 1.0844 Acc: 0.7270\n","\n","Epoch 111/200\n","----------\n","train Loss: 0.6857 Acc: 0.8175\n","val Loss: 1.0861 Acc: 0.7294\n","\n","Epoch 112/200\n","----------\n","train Loss: 0.6718 Acc: 0.8198\n","val Loss: 1.0862 Acc: 0.7310\n","\n","Epoch 113/200\n","----------\n","train Loss: 0.6877 Acc: 0.8159\n","val Loss: 1.0797 Acc: 0.7267\n","\n","Epoch 114/200\n","----------\n","train Loss: 0.6836 Acc: 0.8171\n","val Loss: 1.0955 Acc: 0.7292\n","\n","Epoch 115/200\n","----------\n","train Loss: 0.6838 Acc: 0.8188\n","val Loss: 1.1002 Acc: 0.7292\n","\n","Epoch 116/200\n","----------\n","train Loss: 0.6826 Acc: 0.8188\n","val Loss: 1.1016 Acc: 0.7257\n","\n","Epoch 117/200\n","----------\n","train Loss: 0.6693 Acc: 0.8220\n","val Loss: 1.0893 Acc: 0.7272\n","\n","Epoch 118/200\n","----------\n","train Loss: 0.6673 Acc: 0.8220\n","val Loss: 1.0916 Acc: 0.7265\n","\n","Epoch 119/200\n","----------\n","train Loss: 0.6622 Acc: 0.8233\n","val Loss: 1.1027 Acc: 0.7278\n","\n","Epoch 120/200\n","----------\n","train Loss: 0.6651 Acc: 0.8232\n","val Loss: 1.0996 Acc: 0.7261\n","\n","Epoch 121/200\n","----------\n","train Loss: 0.6678 Acc: 0.8214\n","val Loss: 1.0939 Acc: 0.7293\n","\n","Epoch 122/200\n","----------\n","train Loss: 0.6589 Acc: 0.8245\n","val Loss: 1.0992 Acc: 0.7284\n","\n","Epoch 123/200\n","----------\n","train Loss: 0.6627 Acc: 0.8242\n","val Loss: 1.0969 Acc: 0.7316\n","\n","Epoch 124/200\n","----------\n","train Loss: 0.6453 Acc: 0.8279\n","val Loss: 1.1024 Acc: 0.7284\n","\n","Epoch 125/200\n","----------\n","train Loss: 0.6558 Acc: 0.8250\n","val Loss: 1.0943 Acc: 0.7301\n","\n","Epoch 126/200\n","----------\n","train Loss: 0.6546 Acc: 0.8244\n","val Loss: 1.0888 Acc: 0.7307\n","\n","Epoch 127/200\n","----------\n","train Loss: 0.6568 Acc: 0.8255\n","val Loss: 1.1005 Acc: 0.7288\n","\n","Epoch 128/200\n","----------\n","train Loss: 0.6536 Acc: 0.8253\n","val Loss: 1.1113 Acc: 0.7266\n","\n","Epoch 129/200\n","----------\n","train Loss: 0.6487 Acc: 0.8271\n","val Loss: 1.0976 Acc: 0.7289\n","\n","Epoch 130/200\n","----------\n","train Loss: 0.6503 Acc: 0.8268\n","val Loss: 1.0973 Acc: 0.7285\n","\n","Epoch 131/200\n","----------\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-952d8b1fa867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontinued_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcontinued_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinued_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-965e6a78713b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, from_epoch)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["scratch_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","scartch_model = scratch_model.to(device)\n","scratch_optimizer = optim.Adam(scratch_model.parameters(), lr=0.001)\n","scratch_criterion = nn.CrossEntropyLoss()\n","num_epochs = 100\n","_,scratch_hist = train_model(scratch_model, data_loader, scratch_criterion, scratch_optimizer, num_epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Htr-PSkUNYNN","outputId":"affaf072-a063-4e31-810c-188fa5100cdc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","----------\n","train Loss: 4.2111 Acc: 0.0588\n","val Loss: 3.8980 Acc: 0.0987\n","\n","Epoch 2/100\n","----------\n","train Loss: 3.8680 Acc: 0.1066\n","val Loss: 3.5151 Acc: 0.1650\n","\n","Epoch 3/100\n","----------\n","train Loss: 3.5631 Acc: 0.1561\n","val Loss: 3.9060 Acc: 0.2070\n","\n","Epoch 4/100\n","----------\n","train Loss: 3.2900 Acc: 0.2034\n","val Loss: 3.3332 Acc: 0.2687\n","\n","Epoch 5/100\n","----------\n","train Loss: 3.0730 Acc: 0.2464\n","val Loss: 2.7281 Acc: 0.3078\n","\n","Epoch 6/100\n","----------\n","train Loss: 2.8939 Acc: 0.2818\n","val Loss: 2.5806 Acc: 0.3449\n","\n","Epoch 7/100\n","----------\n","train Loss: 2.7359 Acc: 0.3126\n","val Loss: 2.3918 Acc: 0.3794\n","\n","Epoch 8/100\n","----------\n","train Loss: 2.6379 Acc: 0.3343\n","val Loss: 3.3850 Acc: 0.3917\n","\n","Epoch 9/100\n","----------\n","train Loss: 2.5333 Acc: 0.3566\n","val Loss: 2.4360 Acc: 0.3861\n","\n","Epoch 10/100\n","----------\n","train Loss: 2.4589 Acc: 0.3743\n","val Loss: 2.1706 Acc: 0.4468\n","\n","Epoch 11/100\n","----------\n"]}]},{"cell_type":"code","source":["continued_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","continued_model.load_state_dict(torch.load('./models/2022-08-13 17:18:09.166664/best_weight.pt').state_dict())\n","continued_model = continued_model.to(device)\n","continued_optimizer = optim.SGD(continued_model.parameters(), lr=0.001, momentum=0.9)\n","continued_criterion = nn.CrossEntropyLoss()\n","num_epochs = 50\n","model ,continued_hist = train_model(continued_model, data_loader, continued_criterion, continued_optimizer, num_epochs=num_epochs, from_epoch=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TOYX0ffE1GbI","executionInfo":{"status":"error","timestamp":1660491533733,"user_tz":-480,"elapsed":8045918,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"69c96678-29ef-4eb0-ba9a-5dbc1404108c"},"execution_count":13,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/50\n","----------\n","train Loss: 2.2868 Acc: 0.4152\n","val Loss: 2.1966 Acc: 0.4709\n","\n","Epoch 12/50\n","----------\n","train Loss: 2.2429 Acc: 0.4238\n","val Loss: 2.2699 Acc: 0.4721\n","\n","Epoch 13/50\n","----------\n","train Loss: 2.2215 Acc: 0.4300\n","val Loss: 2.0536 Acc: 0.4805\n","\n","Epoch 14/50\n","----------\n","train Loss: 2.2090 Acc: 0.4310\n","val Loss: 2.0261 Acc: 0.4828\n","\n","Epoch 15/50\n","----------\n","train Loss: 2.1912 Acc: 0.4366\n","val Loss: 2.2163 Acc: 0.4846\n","\n","Epoch 16/50\n","----------\n","train Loss: 2.1926 Acc: 0.4351\n","val Loss: 2.2522 Acc: 0.4842\n","\n","Epoch 17/50\n","----------\n","train Loss: 2.1701 Acc: 0.4386\n","val Loss: 2.1196 Acc: 0.4873\n","\n","Epoch 18/50\n","----------\n","train Loss: 2.1666 Acc: 0.4384\n","val Loss: 2.1146 Acc: 0.4896\n","\n","Epoch 19/50\n","----------\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d6666a5ac15f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontinued_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcontinued_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinued_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-965e6a78713b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, from_epoch)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["scratch_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","scartch_model = scratch_model.to(device)\n","scratch_optimizer = optim.Adam(scratch_model.parameters(), lr=0.001)\n","scratch_criterion = nn.CrossEntropyLoss()\n","num_epochs = 30\n","_,scratch_hist = train_model(scratch_model, data_loader, scratch_criterion, scratch_optimizer, num_epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qsQtND-FCv1","outputId":"0cd100c8-1635-4773-c3b4-359c1abd2b02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","----------\n","train Loss: 4.1211 Acc: 0.0710\n","val Loss: 4.5368 Acc: 0.0988\n","\n","Epoch 2/30\n","----------\n","train Loss: 3.6954 Acc: 0.1331\n","val Loss: 3.6141 Acc: 0.1585\n","\n","Epoch 3/30\n","----------\n","train Loss: 3.3870 Acc: 0.1858\n","val Loss: 3.1569 Acc: 0.2194\n","\n","Epoch 4/30\n","----------\n","train Loss: 3.0752 Acc: 0.2418\n","val Loss: 3.1923 Acc: 0.3070\n","\n","Epoch 5/30\n","----------\n","train Loss: 2.7892 Acc: 0.2974\n","val Loss: 2.9240 Acc: 0.3599\n","\n","Epoch 6/30\n","----------\n","train Loss: 2.5653 Acc: 0.3430\n","val Loss: 2.3477 Acc: 0.3796\n","\n","Epoch 7/30\n","----------\n","train Loss: 2.3955 Acc: 0.3834\n","val Loss: 2.0680 Acc: 0.4496\n","\n","Epoch 8/30\n","----------\n","train Loss: 2.2315 Acc: 0.4176\n","val Loss: 1.8526 Acc: 0.4972\n","\n","Epoch 9/30\n","----------\n","train Loss: 2.1050 Acc: 0.4453\n","val Loss: 1.8564 Acc: 0.5013\n","\n","Epoch 10/30\n","----------\n","train Loss: 2.0025 Acc: 0.4707\n","val Loss: 1.7109 Acc: 0.5341\n","\n","Epoch 11/30\n","----------\n","train Loss: 1.9078 Acc: 0.4933\n","val Loss: 1.5921 Acc: 0.5578\n","\n","Epoch 12/30\n","----------\n","train Loss: 1.8369 Acc: 0.5101\n","val Loss: 1.5673 Acc: 0.5685\n","\n","Epoch 13/30\n","----------\n","train Loss: 1.7570 Acc: 0.5307\n","val Loss: 1.5176 Acc: 0.5847\n","\n","Epoch 14/30\n","----------\n","train Loss: 1.6927 Acc: 0.5398\n","val Loss: 1.5226 Acc: 0.5914\n","\n","Epoch 15/30\n","----------\n","train Loss: 1.6301 Acc: 0.5573\n","val Loss: 1.3880 Acc: 0.6131\n","\n","Epoch 16/30\n","----------\n","train Loss: 1.5710 Acc: 0.5748\n","val Loss: 1.3807 Acc: 0.6154\n","\n","Epoch 17/30\n","----------\n"]}]},{"cell_type":"code","source":["# resnext\n","continued_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","continued_model.load_state_dict(torch.load('./models/2022-08-14 16:21:48.073675/best_weight.pt').state_dict())\n","continued_model = continued_model.to(device)\n","continued_optimizer = optim.Adam(continued_model.parameters(), lr=0.001)\n","continued_criterion = nn.CrossEntropyLoss()\n","num_epochs = 70\n","model ,continued_hist = train_model(continued_model, data_loader, continued_criterion, continued_optimizer, num_epochs=num_epochs, from_epoch=16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"auBK145i-UPe","outputId":"0ac38f3d-2dac-4541-a5e9-a40837fa5e13"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/70\n","----------\n","train Loss: 1.6961 Acc: 0.5403\n","val Loss: 1.3923 Acc: 0.6158\n","\n","Epoch 18/70\n","----------\n","train Loss: 1.6493 Acc: 0.5570\n","val Loss: 1.4110 Acc: 0.6128\n","\n","Epoch 19/70\n","----------\n","train Loss: 1.5827 Acc: 0.5738\n","val Loss: 1.4466 Acc: 0.6243\n","\n","Epoch 20/70\n","----------\n","train Loss: 1.5139 Acc: 0.5862\n","val Loss: 1.2866 Acc: 0.6448\n","\n","Epoch 21/70\n","----------\n","train Loss: 1.4716 Acc: 0.5996\n","val Loss: 1.3010 Acc: 0.6413\n","\n","Epoch 22/70\n","----------\n","train Loss: 1.4310 Acc: 0.6085\n","val Loss: 1.4090 Acc: 0.6364\n","\n","Epoch 23/70\n","----------\n","train Loss: 1.3765 Acc: 0.6239\n","val Loss: 1.2440 Acc: 0.6562\n","\n","Epoch 24/70\n","----------\n","train Loss: 1.3328 Acc: 0.6345\n","val Loss: 1.2198 Acc: 0.6648\n","\n","Epoch 25/70\n","----------\n","train Loss: 1.2976 Acc: 0.6430\n","val Loss: 1.2375 Acc: 0.6607\n","\n","Epoch 26/70\n","----------\n","train Loss: 1.2464 Acc: 0.6571\n","val Loss: 1.1812 Acc: 0.6813\n","\n","Epoch 27/70\n","----------\n","train Loss: 1.2057 Acc: 0.6648\n","val Loss: 5.5659 Acc: 0.5657\n","\n","Epoch 28/70\n","----------\n","train Loss: 1.1779 Acc: 0.6741\n","val Loss: 1.6104 Acc: 0.6441\n","\n","Epoch 29/70\n","----------\n","train Loss: 1.1400 Acc: 0.6830\n","val Loss: 1.2094 Acc: 0.6862\n","\n","Epoch 30/70\n","----------\n","train Loss: 1.1334 Acc: 0.6845\n","val Loss: 1.2353 Acc: 0.6785\n","\n","Epoch 31/70\n","----------\n"]}]},{"cell_type":"code","source":["# resnext\n","continued_model = initialize_model(model_name, num_classes, use_pretrained=False)\n","continued_model.load_state_dict(torch.load('./models/2022-08-15 16:26:33.793275/best_weight.pt', map_location=torch.device('cpu')).state_dict())\n","continued_model = continued_model.to(device)\n","continued_optimizer = optim.Adam(continued_model.parameters(), lr=0.0005)\n","continued_criterion = nn.CrossEntropyLoss()\n","num_epochs = 70\n","model ,continued_hist = train_model(continued_model, data_loader, continued_criterion, continued_optimizer, num_epochs=num_epochs, from_epoch=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"pvUiR1j1_h2A","executionInfo":{"status":"error","timestamp":1660596097829,"user_tz":-480,"elapsed":3994068,"user":{"displayName":"陳瑞柏","userId":"07541614533607343153"}},"outputId":"6349a2f4-957b-420f-9887-e1d0b2c023c2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 31/70\n","----------\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-abf780eacf4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcontinued_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcontinued_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinued_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinued_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-12f75c0e0273>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, from_epoch)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}